---
layout: single
title: "CUDA Environment setup, Ubuntu"
categories: cuda
tags: [language, programming, cpp, cuda, Ubuntu]
toc: true
author_profile: false
sidebar:
    nav: "docs"
search: true

---

*CUDA Environment Setup*


# CPP 컴파일 환경 설정
- 프로젝트 디렉토리 설정
    - 프로젝트 디렉토리를 VS Code에서 연다
- 작업 환경
    - tasks.json: 빌드 작업 설정. 컴파일러 명령 및 링크 설정
    - c_cpp_properties.json: C++ 프로젝트의 intellisense 구성 설정. 컴파일러 경로와 표준 라이브러리 경로
    - .vscode/settings.json: 프로젝트 또는 사용자 설정 지정. 경로 관련 설정 추가 가능 



# CU 컴파일 환경 설정

- nvcc 설치

```bash
sudo apt-get update
sudo apt-get install nvidia-cuda-toolkit
// 확인
nvcc --version
nvidia-smi
```

- cpp 컴파일 환경 설정과 마찬가지로, 프로젝트 디렉토리에 .vccode 폴더 생성 후 tasks.json 파일을 만든다.

```
// tasks.json
{
    "version": "2.0.0",
    "tasks": [
        {
            "label": "build",
            "type": "shell",
            "command": "nvcc",
            "args": [
                "main.cu",          // .cu 파일 이름
                "-o",
                "my_cuda_program"  // 생성된 실행 파일 이름
            ],
            "group": {
                "kind": "build",
                "isDefault": true
            },
            "presentation": {
                "reveal": "always",
                "panel": "shared"
            },
            "problemMatcher": "$nvcc"
        }
    ]
}
```

- 컴파일

```
cntrl + shift + B
```

- 실행

```bash
./my_cuda_program
```

- 테스트 코드: cudaDeviceProp 구조체를 이용해서 property 가져오기

```c
#include <iostream>
#include <cuda_runtime.h>
#include <helper_cuda.h> // _ConvertSMVer2Cores(deviceProp.major, deviceProp.minor)

int main() {
    int deviceCount;
    cudaGetDeviceCount(&deviceCount);

    for (int deviceIdx = 0; deviceIdx < deviceCount; ++deviceIdx) {
        cudaDeviceProp deviceProp;
        cudaGetDeviceProperties(&deviceProp, deviceIdx);

        std::cout << "Device " << deviceIdx << ": " << deviceProp.name << std::endl; // char[255]
        std::cout << "  Compute Capability: " << deviceProp.major << "." << deviceProp.minor << std::endl; // compute capability 주 버전. 마이너 버전. 둘 다 int
        std::cout << "  Multiprocessors: " << deviceProp.multiProcessorCount << std::endl; // SM 갯수
        std::cout << "  CUDA Cores per Multiprocessor: " << deviceProp.warpSize << std::endl;
        std::cout << "  CUDA cores: " << _ConvertSMVer2Cores(deviceProp.major, devProp.minor * deviceProp.multiProcessorCount);
        std::cout << "  Global Memory: " << deviceProp.totalGlobalMem / (1024 * 1024) << " MB" << std::endl; // GPU의 global(device) 메모리 크기. 단위 byte
        std::cout << "  Shared Memory per Block: " << deviceProp.sharedMemPerBlock / 1024 << " KB" << std::endl;
        std::cout << "  Max Threads per Block: " << deviceProp.maxThreadsPerBlock << std::endl;
        std::cout << "  Max Threads per Dimension: (" << deviceProp.maxThreadsDim[0] << ", "
                  << deviceProp.maxThreadsDim[1] << ", " << deviceProp.maxThreadsDim[2] << ")" << std::endl;
        std::cout << "  Max Grid Size: (" << deviceProp.maxGridSize[0] << ", " << deviceProp.maxGridSize[1] << ", "
                  << deviceProp.maxGridSize[2] << ")" << std::endl;
        std::cout << std::endl;
    }

    return 0;
}
```

# GTX 960
```c
Device 0: NVIDIA GeForce GTX 960
  Compute Capability: 5.2
  Multiprocessors: 8
  CUDA Cores per Multiprocessor: 32
  Global Memory: 4043 MB
  Shared Memory per Block: 48 KB
  Max Threads per Block: 1024
  Max Threads per Dimension: (1024, 1024, 64)
  Max Grid Size: (2147483647, 65535, 65535)
  Tensor Core 지원: No
```

# RTX 3060
```c
Device 0: NVIDIA GeForce RTX 3060
  Compute Capability: 8.6
  Multiprocessors: 28
  CUDA Cores per Multiprocessor: 32
MapSMtoCores for SM 8.168 is undefined.  Default to use 128 Cores/SM
  CUDA cores: 128  Global Memory: 12287 MB
  Shared Memory per Block: 48 KB
  Max Threads per Block: 1024
  Max Threads per Dimension: (1024, 1024, 64)
  Max Grid Size: (2147483647, 65535, 65535)
```

- Ray tracing, 메모리 버스 너비, 클럭 속도, AI 및 machine learning 지원 여부 확인 요망

# CUDA 프로그램 분석 도구
- [https:://developer.nvidia.com/tools-overview](https:://developer.nvidia.com/tools-overview)
