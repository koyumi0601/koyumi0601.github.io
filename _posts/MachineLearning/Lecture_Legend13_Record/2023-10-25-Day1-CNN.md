---
layout: single
title: "CNN"
categories: machinelearning
tags: [ML, Machine Learning, AI, Legend13]
toc: true
author_profile: false
sidebar:
    nav: "docs"
search: true


---

*Legend 13 (Image)  Voice Transciption*

# Summary
- 

# Transcription
- 클로바노트 https://clovanote.naver.com/


##### 받아쓰기
참석자: 참석자(여) 참석자(남) 강사

##### Page 2 4:45

![Legend 13-002]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-002.jpg)

이런 거에서 나왔던 내용이에요. 어쨌든 그래서 cnn의 기본 내용 그리고 기본 내용을 통해서 여러분들이 뭔가 얻어가실 수 있는 게 또 있거든요. 
보도록 하겠습니다. 

##### Page 3 5:00

![Legend 13-003]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-003.jpg)

이런 건 됐고 Yolo로 같은 거 오브젝트 디텍션 같은 게 많이 유명하죠 이렇게 네모 네모 박스쳐가지고 이거는 말하자면 회귀랑 분류 문제 섞어서 푼 거죠. 
분류도 하고 박스 x y w h 중심 좌표랑 w h 알아내 가지고 회귀랑 분류 저 같이 푸는 그런 식으로 풀면은 할 수 있는데 어쨌든 관건은 뭐예요? 이미지 인식에 있어서는 cnn이 잘한다. 그래서 이런 오브젝트 디텍션 문제를 풀 적에도 cmn 같은 거를 써봄직하다 쓰는 게 꽤 꽤 성능이 좋다. 이런 이야기들인 거죠. 



![Legend 13-004]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-004.jpg)

좋습니다. 근데 cnn이 과연 어떻게 이렇게 잘 동작을 하는지 인간의 사고 방식을 잘 흉내낸 거거든요. 



어떻게 했길래 이렇게 잘 동작을 하는지 그거를 말씀드려볼까요? 신경다발을 잘 끊어냈다라고 일축 말씀을 드릴 수가 있어요. 
그러니까 이미지가 있으면 모든 픽셀을 다 연결하려고 하지 말고 일부만 연결해라. 로컬 로컬 정보 이런 얘기 들어보셨을 거예요. 
이미지를 인식할 때 뇌를 전부 다 쓰는 게 아니더라. 일부만 활성화가 돼가지고 이미지를 인식하더라라는 어떤 그런 실험 결과 그런 걸 좀 통해서 이걸 다 반영을 해 준 거고 



그런 거예요. 모든 픽셀을 다 연결하는 fully connected들 모든 픽셀을 다 연결해가지고 보려고 하는 것이 과연 이 이미지 인식을 잘 하는 것이냐. 잘하는 게 아니다. 
어떻게 해야 잘하는 건데. 특징을 추출하는 게 잘하는 거예요. 



이미지라고 하면 위치별 특징 여기에 코가 있네 여기에 눈이 있네 이런 식으로 특징을 추출 특징이 존재하고 뭐 혹은 패턴이라고 말할 수 있는 거예요. 
그런 것을 찾아내서 object detection을 하든 classification을 하든 하셔라라는 겁니다. 그중에 가장 설명이 쉬운 거 분류 문제 classification 문제를 중점적으로 설명을 드려볼까 합니다.  이 강의 전체에서는 



좋습니다. 이 패턴이라 함은 왜 패턴이 중요하냐 AI 이 머신은 패턴의 존재 자체를 몰라요. 그냥 사진을 보여줄 뿐이에요. 근데 어떻게 구별을 잘 하겠습니까 하겠습니까? 방금 태어난 아기한테 강아지 고양이를 분류해보라고 하면 당연히 동물이라는 것 그 자체를 몰라요. 그러다 보니까 계속 그냥 몇 만 장 보다 보니까 뭔가 이렇게 큰 패턴이 있고 작은 패턴이 있고 뭔가 이렇게 오밀조밀 존재를 하는 픽셀 값들이 막 존재하는 게 아니고 라는 거예요. 

마침 근데 convolution이라는 연산은 위치별 패턴을 찾아주는 연산이에요. 찾는 연산. 그렇기 때문에 그거를 인공신경망에 적용한다. 

그것만으로도 자 내가 지금 지금부터 보여줄 입력 숫자들 행렬이죠 사진은 그냥 행렬이죠. 

그 행렬에는 단순히 그냥 숫자가 뿌려져 있는 게 아니고 위치의 패턴이 있다 라는 그런 어떤 사전 정보를 잘 심어준 거예요. 



사전 정보가 딥러닝 전체에서 가장 중요한 키워드라고 볼 수 있는 거예요. 사전 정보. 귀띔이라고 볼 수가 있습니다. 

Cnn은 컨벌루션이라는 걸 통해서 ai한테 로컬 정보를 중요하게 봐라. 위치별 특징을 좀 뽑아가면서 그 특징을 비교를 해라. 강아지는 어떤 특징이 있고 고양이 어떤 특징이 있으니까 이 사진은 강아지네 이런 식으로 인식을 해라라고 귀띔을 해주는 거다라는 거야. 
convolution을 쓴다라는 거죠. 오케이





![Legend 13-005]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-005.jpg)

fully connected를 넣으면 뭐가 문제가 될까요? 여러분
하진님 뭐가 문제가 되는 거예요? fully connected를 넣으면

너무 많은 정보를 한번에

참석자2(남) 
한번에 들어가서 과적합이랑

참석자3(여) 
위치 정보가 손실되는

(강사)

어떻게 된 거예요 



(여) 위치정보가



(강사) 너면 어떻게 되는 거죠? 너무 어떤 어떤 느낌이죠? 아 소리를 꺼놨네. 
영상 아까 영상 재생되는 거 소리 끊으라고 죄송해요. 
하진님이 뭐라고 하셨어요 



(남) 너무 많은 정보가 입력돼 가지고 과적합이 일어난다.



(강사) 그렇죠



(강사)
불필요하게 너무 많은 정보요. 쓸데 없이 많은 정보랄까 근데 정보량 자체로 놓고 봤을 때는 cnn도 모든 픽셀을 결국에 정보를 보긴 봐요. 
근데 나중에 보죠. 그러니까 일단은 좁은 영역에서 먼저 보고 나중에 멀리 있는 것을 보는 어떤 그런 약간 단계적인 행위를 한다라는 거고 우리 저기 다솔님은 뭐라고 하셨어요? 못 들었어요



참석자2(여) 
그 위치 정보를 상실해서

강사 
이거 수준 굉장히 높다. 이번에 
그렇습니다. 
위치 정보도 잃고 쓸데 없이 너무 세세하게 본다라는 거예요. 
무슨 진품명품 아니라 딱 보고 강아지 고양이 이렇게 알아맞춰야 되는데 뭔 진품명품 아냐 이거 진품명품 알아요 다솔님



참석자3(여) 
네



강사 05:18
그럼 나랑 비슷한 연배구만. 그렇습니다. 
진품명품이 뭐냐 하면 이걸 들고 나와요. 
집에서 이걸 들고 나요. 이게 한 1800년대에 만들어진 애플 펜슬이라고 주장하는 거죠. 
예를 들면 이게 엄청 고려 청자 같은 거예요. 
근데 그게 가짜면은 감정가를 매기는 거죠. 



그런 저기 TV 프로인데 그런 거면 돋보기를 들고 와서 엄청 세세하게 봐야 돼요. 

그럴 때는 어떻게 보면 fully connected가 맞을지도 몰라요.

근데 우리가 풀고자 하는 거는 그냥 이거의 종이에요. 

종 뭐 그냥 강아지 포메라니안 이런 식으로 알고 싶은 거니까 그렇게 세세하게 볼 필요가 없다라는 겁니다. 



![Legend 13-006]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-006.jpg)

![Legend 13-007]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-007.jpg)

그리고 말씀하신 그 위치 정보 그래요. 
fully connected라 하면 이렇게 연결돼 있으나 이렇게 연결돼 있으나 이렇게 어쩌라는 거예요 이렇게 어 섞어도 성능에 차이가 없겠다라는 거예요. 
섞고 학습을 시켜도 성능의 차이가 없겠다. 
이렇게 웨이트 1 웨이트 2
이렇게 웨이트1 웨이트2 

차이가 없다라는 겁니다. 

이런 두 가지의 어떤 문제점이 있다라는 거고

 로컬한 정보 그러니까 이쯤에 뭐가 있고 이쯤에 주황 털이 있네 이쯤에 하얀 털이 있네 이쯤에는 눈이 있네 이런 식으로 인식하게끔 해야 된다. 
그런 식으로 인식하게끔 가이드를 잘줘야 된다라는 거지. 

위치 매치가 중요하다라고 알려줘야 되는데 그걸 어떻게 알려주냐 바로 그게 컨벌루션이다. 

![Legend 13-009]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-009.jpg)

컨벌루션은 특징을 추출하는 그런 연산입니다. 그래서 이걸 이용하면 코가 여기 있네 눈이 여기 있네 뭐 입이 여기 있네 뭐 이런 식으로 알게 된다 라는 겁니다





일단 예시로 다 알 만한 내용입니다.



 ![Legend 13-010]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-010.jpg)

이거에 대해서 3 by 3자리 행렬이라고 쳐요. 여기에 대해서 컨벌루전 어떻게 합니까? 이 부분만 연결한다. 그리고 웨이트를 곱한다. 여러분들이 알고 있는 그 인공신경망이죠 근데 커넥션을 좀 끊어낸 거죠. 이 부분만 연결했고 나머지는 끊어낸다. 



그러고 나서는 이동시켜서 웨이트 곱하고 더하고 그다음에는 오른쪽으로 쭉 갔으면 이제는 왼쪽 아래로 내려가서 또 긋는 거예요. 그러니까 스캔하는 거예요. 스캔. 같은 웨이트 셋으로 흡수하게 된다 모으게 된다라는 거 그런 정보 로컬한 정보만 보게 된다. 





![Legend 13-011]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-011.jpg)

그래서 이렇게 함으로써 얻는 효과가 바로 그 위치 정보를 잃지 않는다라는 거예요. 
가까이 있는 것들만 연결했기 때문에. 그래서 이건 담당한다라는 거예요. 
담당 어딘가를 담당. 위치를 담당하게 되는 그런 새로운 의미가 생기는 거예요. 
fully connected였으면 그런 게 어디 있습니까? 그런 게 어디 있어요
fully connected 다 연결돼 있는데 어디를 담당하고 그런 얘기가 없죠 근데 convolution은 이렇게 어떤 특정 위치를 담당하게끔 할 수 있다라는 거예요. 
연결을 다 연결하지 않고 일부분 끊어냄으로써 이게 가능해졌다 라는 거고요. 



![Legend 13-012]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-012.jpg)

이렇게 웨이트들을 이렇게 모아가지고 우리는 필터 혹은 커널이라고 부르죠. 
이런 용어들은 익숙하실 겁니다. 바이어스도 물론 다 있는 거예요. 
그래서 그림에서 생략했지만 물론 얘도 재사용해가지고 웨이트 셋으로 치는 거죠. 
그래서 이렇게 5개 값이 곱하고 더 하고 밀고 곱하고 더하고 밀고 곱하고 더하고 좋습니다. 
여기까지 괜찮습니까? 두 분? OK 나이스 



![Legend 13-013]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-013.jpg)

그런데 이 convolution은 연산이 중요한 것이 특징을 추출하는 게 중요한 지점이라고 했어요. 
어떻게 어떻게 추출하는데 그거를 말씀 안 드렸죠. 여기서 한번 보여드릴까 합니다. 



왼쪽 아래의 그림은 왼쪽 부분이 어둡고 오른쪽 이 밝은 이미지예요. 
그렇죠? 그러면은 세로 특징이 있는 그런 이미지라고 볼 수 있겠네. 
거기다 내고 컴벌루션 이게 컴블루션 기호예요. 
컴블로션 기호. 이러한 필터 이러한 필터 이게 웨이트를 모아놓은 거죠. 

이러한 필터를 convolution 한다라는 것은 얘네가 곱하고 더하고 밀고 곱하고 더하고 이거를 하겠다는 거예요. 바이어스는 생략하겠습니다. 곱하고 더하고 밀고 곱하고 더하고 밀고 쭉 스캔하면서 필터랑 비슷한 패턴을 찾는 거예요. 이거는 

곱하고 더하고 밀고 곱하고 더하고 밀고 이거는 현상만 아까 말씀드렸는데 그 행위가 뭐냐라고 하면 내적이다라는 거예요.



내적. 우리 To the transformer 들으신 분들 귀가 따갑게 들었죠 내적은 닮은 정도로 얘기한다라고 했어요. 
그러니까 이 패턴과 다른 패턴이 어디에 있나 어텐션 하는 거예요. 
예 이것도 어텐션이야. 딴딴딴딴딴딴 딴딴딴딴딴딴 가면서 이 필터랑 비슷한 녀석이 누가 있는가 돌아다니는 겁니다. 
돌아다니는 거예요.



한번 해보겠습니다. 

여기다가 올라 태웠어요. 이렇게 싹 올라탔습니다. 
여기에 웨이트를 써놨어요. 빨갛게. 그러면 곱하고 더하면

시작.
9개 값 싹 곱하고 그냥 싹 더해버리세요. 그러면은

(여) 10:05
0

강사 10:06
(강사) 0이 나온다. 여기다 써준 거. 그다음에 한 칸 이동합니다. 
그죠? 아까 그 그림이야. 아까 그 그림. 한칸 이동. 곱하고 더합니다. 
그러면 시작. 
(남) 3
(강사) 그렇습니다. 바로?
(여) 4
(강사)오케이 바로 이어서? 
(여) 0 
(강사) 한 번 더 
(여) 0
(강사) 그러면 얘를

강사 10:28
왼쪽 아래로 이동했기 때문에 그 위치에 맞게 써준다라는 거예요. 
이것도 꽤나 중요한 포인트입니다. 그 위치 정보를 잃지 않기 위해서 시프트되는 그것을 반영해가지고 저기다가 숫자들을 놓는 거예요. 
아무렇게나 그냥 쌓는 게 아니고 그것도 중요한 포인트요. 
또 이동. 어떻게 된다?

참석자2(남) 10:44
삼 삼 삼

강사 10:49
(남) 0
(강사) 좋습니다. 답이 나왔어요. 어떤 특징이 어디에 그리고 얼만큼 강하게 있는지까지 얘기해 줄 수 있다는 거예요. 
이게 바로 특징을 추출하는 거다라는 얘기죠. 
자 어떻게 답하실 수 있습니까? filter 1은 어떤 특징을 찾으려고 돌아다니는 애 같아요? filter 1은? 딱 보면?

어떤 패턴을 나타내는 것 같습니까? filter1이 가로세로 중에


양보하지 말고 양보 안 해도 돼요. 대답 양보 안 해도 돼요.


세로죠 좋습니다. 제이임님께서 아주 잘 대답해 주세요. 

세로 특징을 뽑는 거예요. 세로 특징이 어디에 얼만큼 강하게 있는데요. 

얘를 convolution 했더니 그걸 답 할 수 있게 돼 있어요. 

어디에 얼마큼 강하게 있습니까?

강사 11:51
왼쪽 가운데 오른쪽 중에 어디에 있습니까? 가운데에 얼만큼 강하게 있습니까?



강사 12:03
이 패턴이 얼만큼 강하게 있다라고 볼 수 있습니까? 1입니까 2입니까 3입니까 4입니까 5입니까? 정확히 숫자로 얘기해줄 수도 있다는 거예요. 
3만큼 강하게 있다. 딱 요것까지 얘기해 줄 수 있다는 거야. 

그러니까 특징을 추출한다. 딱 보여드린 거죠. 연산을 통해서. 그러면 얘는 무슨 특징을 찾는 거예요



참석자3(여) 12:24
가로

강사 12:25
가로 특징을 찾아야 겠어요. 여기 돌아다녀요. 
이거를 해보면, 마찬가지로 또 곱하기 더하고 해보셔야겠죠 이렇게 나와요. 
그 말은 가로 특징이 어디에도 없다. 
이게 된다는 거에요. 





![Legend 13-014]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-014.jpg)

자 transpose 시켜봤어요. 이거 행렬을 뒤집어 봤습니다. 
거기다 대고 필터링을 했을 때, 이번에는 세로 특징이 어디에도 없고 가로 특징이 가운데에서 3만큼, 이렇게 나오더라는 거예요. 
그러니까

강사 12:52
진짜 신기하게 자기랑 비슷한 패턴을 잘 찾으면서 돌아다니는구나 이걸 알 수가 있었고 





![Legend 13-015]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-015.jpg)

이미지에다가 실제로 해봤습니다. 
이렇게 나오고 이렇게 나왔어요. 근데 이렇게만 보면은 알기가 힘들어서 쓱 이 부분 확대합니다. 
보였어요? 봤어? 뵹 확대했어. 자 지붕은 가로 특징이 좀 많은 애고 굴뚝은 새로 특징이 많은 앱니다. 
그리고 진한 게 특징이 그 특징이 많다라고 보면 돼요. 
까만색으로 갈수록 진한 거니까.


자, 필터 1의 결과를 보니까 지붕의 세로 특징이 많네. 
필터 2의 결과를 보니까 어디에 가로 특징이 많아요?


지붕 굴뚝 중에 어디의 가로 특징이 지붕에 있죠 그래서 가로 지붕 구분이 진하게 나온 겁니다. 

바로 그거예요. 



![Legend 13-016]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-016.jpg)

근데 convolution이 있고 이제 필터링이라고 하면 꼭 이렇게 특징을 추출하는 뽑아내는 느낌만 있는 건 아니고 변형을 가하기도 해요. 
그래서 이렇게 생긴 애를 convolution하면 이렇게 됩니다.


그런 그런 느낌 



![Legend 13-017]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-017.jpg)

그리고 말씀드렸듯이 이렇게 세로 얘는 세로 특징을 뽑는 거죠. 
이렇게 세로 특징을 뽑고 바이어스도 더해야겠죠 바이어스도 더하고 이렇게 결과 



그리고 가로 특징도 뽑고 이렇게 이렇게 결과 



그다음에 대각성 특징도 뽑고 이런 이런 식으로 여러 특징을 뽑을 수가 있는 겁니다. 그렇죠

(강사) 왼쪽이 하나의 이미지에 다 대고 여러 특징을 뽑았어요. 
그러면 이렇게 나온 결과물들을 특징 맵이라고 부릅니다. 

피처 맵 피처 맵. 뭐라고요? 

(남, 여) 피처 맵

(강사) 피처 맵 좋습니다. 

특징 맵 피처 앱 모두 좋습니다. 그런데 얘네들을 잘 가지고 있어야 해요. 이 정보를.

그렇다 보니까 얘네들은 합친다거나 그렇지 않고 depth축으로 쌓습니다. 
concatenation을 해요. 



그래서 첫 번째 채널은 세로 특징을 뽑은 피처맵이야. 
두 번째 두 번째 피처맵은 가로 특징을 뽑은 피처맵이야. 
이런 식으로 피처 맵이라는 의미를 담을 수 있도록 하는 거예요. 
만약에 얘들을 그냥 더해버리면 얘는 무슨 특징을 뽑은 건지 몰라요.

가로 특징 뽑고 세로 특징 뽑고 대각선 특징 뽑고 그걸 더해버렸으니까 뭉뚱그려져 버렸죠 
그래서 이쪽 channel 축으로 쌓아주셔야 된다 라는 겁니다. 



중요한 점은 바로 이거예요. 
여기서 보여드리는 kernel속의 값. 이것들이 바로 뭐다? weight. 그리고 이게 뭐다? bias. 학습 파라미터라는 거예요. 

그냥 인공신경망이고 convolution 이라는 일부 신경만을 끊어내는 현상을 적용했을 뿐입니다. 

그래서 그냥 여기 있는 weight bias도 마찬가지로 학습해야 될 존재고 얘네들에 대해서 gradient구하시고 back propagation 하는 그 과정을 해야 돼요. 
지금은 저는 예시를 들기 위해서 굳이 변수를 쓰지 않고 숫자를 넣어드렸습니다만 얘네들은 내가 정해줄 값이 아니고 ai가 학습해 나가는 그런 값이다라는 겁니다. 
이게 굉장히 중요한 포인트인데 왜 그러냐면 다음 페이지에서 한번 설명드려볼게요. 
자 일단 정리. 



![Legend 13-018]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-018.jpg)

주변만 연결한다 weight 재사용한다 여러 종류의 특징을 추출한다. 
여기까지 얘기를 했던 거고 



그리고 거기 속에 들어가는 필터 속에 들어가는 값이 학습 파라미터라는 것은 이렇게 얘기를 할 수 있게 되는 거예요.


각 필터가 어떤 특징을 추출할지를 내가 아니고 AI 네가 알아내라 이렇게 얘기를 하면 된다는 거예요. 
그냥 weight 업데이트에요. 그냥 여태까지 해놓는 그냥 gradient descent 뭐 그냥 똑같은 그건데 convolution을 적용했더니 얘가 비슷한 패턴을 찾는 연산이다 보니까 어떤 패턴을 추출해야 loss를 잘 줄일지를 학습하는 셈이네.


곧, 어떤 특징을 추출해서 분류를 해야 잘 분류를 할까 그 고민을 내가 아니고 ai가 해준다라는 거예요. 

단순히 convolution을 썼을 뿐인데 이런 해석이 가능하다는 겁니다. 

놀랍지 않습니까? 아닌가? 예




단순히 어쨌든 곱하고 더하고 activation 그리고 밀고 또 곱하고 더하고 activation 그리고 밀고 이게 다야. 

그런데 저런 의미까지 해석해줄 수가 있다. 담아낼 수가 있다는 점이 바로 놀라운 점이다라는 겁니다. 

여기까지 됐습니까? 여기까지 되셨으면은 파란색 버튼 눌러주시고 아직 안 됐으면은 저기해주시고 질문 한번 해주시고 눌러주세요. 여러분 눌러도 됩니다. 오케이 잘했어요. 



![Legend 13-019]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-019.jpg)

시작해 봅시다.
질문이 있었나요? 방금 아닌가? 괜찮나요? 



자, 칼라 사진일 때 이거를 좀 많이 헷갈려 하시거든요. 
잘 들어보세요. RGB 3개 채널 있는 그런 컬러 사진을 넣었을 때는, 기억하세요. 
무조건 앞에 거 채널 수에 맞추세요. 
무조건 앞에 거로 채널 수에 맞추세요. 
뭐를? 필터의 채널 수 필터의 채널 수는 무조건 앞에 거의 채널 수에 맞추 세요. 
그래서 여기다가 convolution할 필터의 채널 수는 몇 개?

강사 18:29
세 개의 채널을 가지는 필터가 필요한 거예요. 
그래서 저기 빨갛게 써 있는 3은 정해지는 거고요. 
5 by 5 저거는 정해 주시는 겁니다. 하이퍼 파라미터 

3은 하이퍼 파라미터가 아니고요. 

5 by 5는 하이퍼 파라미터입니다. 여러분들이 정해주셔야 되는 그 파라미터요. 

좋습니다. 여러

얘를 가지고 왜 왜 채널 개수가 맞아야 될까요? 하신다면 이렇게 답하면 돼요. 

올라타야 되니까 올라타서 곱하고 더해야 되는데 채널 개수가 안 맞으면 못 올라 타잖아요. 

물론 3d 컨볼루션은 조금 다른 얘기이긴 합니다만 어쨌든 2d 컨볼루션 하려면 채널 기수가 딱 일치가 돼야 된다라는 겁니다. 

그래야 이렇게 싹 올라타서 곱하고 더하고 밀고 곱하고 더 하고 밀고 곱하고 더하고 밀고. 이렇게 convolution을 할 수가 있으니까 그래서 채널 갯수를 맞춰줘야 된다라는 것이고 



자 그러면은 곱하고 더하고 밀고 곱하고 더하고 밀고 이렇게 곱하고 더하고 하나의 값. 밀고 곱하고 더하고 하나의 값. 그거를 쭉 밀면서 결과물을 만들게 될거예요.

그 그 결과물의 채널 수는 어떻게 될까요? 몇 개가 될까요? 

하나죠 하나의 특징을 뽑았어요. 하나의 특징 맵이 나온 겁니다. 

끝. 

근데 이렇게 세 개의 채널을 가지는 필터는 좋은 게, 앞에 게 칼라다. 

예를 들면 칼라면은 이렇게 얘기할 수 있는 거예요. 

아까는 세로 가로 이거였는데 빨간색 세로. 노란색 가로. 초록색 대각선. 뭐 이런 식으로 어떤 색깔 특징을 뽑아낼 수도 있게 되는 겁니다. 

채널 축으로도 필터가 존재한다는 것이 어떤 그런 이점을 가진다는 거예요. 

아 물론 3 by 5 by 5면은 75개의 값이 weight파라미터인 거예요. 

75개입니다. 저기 색깔 칠해져있다고 다 weight 3개 아닙니다. 

3 곱하기 5 곱하기 5 전부 다 다 따로 학습되는 파라미터 들이에요. 



좋습니다. 

자 두 번째 필터로 convolution할 때 채널 개수 몇 개 해야 될까요?

또 다른 필터를 가지고 오고 싶어요. 

또 다른 특징을 뽑고 싶으니까. 세 개죠. 또 다른 한 개인 거예요. 

두 개의 필터를 사용했어요. 두 개의 필터를 사용했기 때문에 채널이 개수가 어떻게 되는 거예요? 

두 개. 이 말은 두 개의 특징을 뽑아서 두 개의 특징 맵을 얻었다 그겁니다. 

그거예요. 그게 답입니다.



그리고 fully connected도 여러 번 layer를 통과하듯이 컨벌루션 레이어도 마찬가지입니다. 
여러 번 레이어 통과하실 수 있고요. 
자 여기서 문제 얘랑 convolution 하려면 두 번째요. 
두 개의 채널을 가지는 결과물 에다가 convolution하려면 채널의 개수 몇 개여야 됩니까? 필터의 채널의 개수는?



강사 21:26
(남) 두 개 입니다. 
(강사) 아주 잘 세뇌가 됐어요. 
바로 앞에 거에 맞춰줘야 된다라는 거예요. 
이렇게 
3 by 3은 무슨 파라미터다? 

(남) 하이퍼 파라미터요

(강사) 하이퍼 파라미터 정해주셔야 되고요. 

2는 정해지는 겁니다. 



오케이 여기에서는 세 개의 특징을 뽑아봅시다. 

그러면 그 결과물 채널의 수는 어떻게 됩니까?



(여) 세 개



강사 21:53
세 개가 되죠 왜? 세 개의 특징 뽑았으니까 세 개의 특징 맵이 나왔다. 

아주 좋습니다. 이게 standard convolution이고 우리 수업 시간에는 depth wise 등 등 여러 가지 convolution을 배워볼 거예요. 



![Legend 13-020]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-020.jpg)

좋습니다. 헷갈려 하시는 분이 조금 있어요. 

그래서 이거를 연습 한 번 해보겠습니다. 

3 by 7 by 7 거기다가 3 by 3짜리 이거는 사이즈, 행렬을 말하는 거야. 행렬



강사 22:17
그 녀석의 채널 수는 어떻게 될까 이건데 일단은 같이 한번 해보도록 하겠습니다. 

이게 3 by 3 짜리가 있다고 치면



참석자2(남) 22:25
오케이

강사 22:26

3 by 7 by 7 짜리 있어요. 여기다가 convolution할 거예요. 

3 by 3 짜리를 convolution 할 거예요. 

그러면은 결과가 어떻게 되냐면 두 개씩 줄어요. 

예를 들어서 8 by 8 짜리가 있다고 쳐요. 

그러면 3 by 3자라가 이리 올라타겠죠 

곱하고 더하고 밀고 곱하고 더하고 밀고 셋 넷 다섯 여섯 아래로도 가겠죠 그러면

강사 22:55
8 바이 8짜리랑 3바이 3짜리 하면은 몇 by 몇이 탄생하는 거예요 그 결과 6 by 6이 되는 거죠. 나이스

두 개씩 깎인다고 보시면 되고 그래서 여기서 보시면은 5 by 5로 일단 깎이게 된다라는 사실은 알려드릴게요. 

그랬을 때 문제 여기에 채널 수 몇이어야 된다 이건 정해진다 그랬습니다.

강사 23:20
3 나이스 이거에 의해서 정해지죠 그게 첫 번째 답이었어요. 

두 번째 

그런 필터를 10종으로 사용한다고 합시다. 

그러면은 웨이트의 shape은 어떻게 표현할 수 있냐면 이렇게 생긴 필터를 10개 썼다. 

그래서 4D 텐서가 나오는 거예요. 10 by 3 by 3 이렇게

강사 23:43
오케이 그래서 제 유행어가 여기서 나옵니다. 
개채행열입니다. 여러분 따라해 보시죠. 
개채행열 개채행열. 한 번 더 마지막으로 여러분 뭐라고요?

강사 24:01
좋습니다. 이건 무슨 말이냐면 행렬은 이거 마지막 행렬 사이즈 얘기해 주는 거고 채는 채널의 수 얘기하는 거고 개는 몇개 몇 개의 이미지냐 혹은 몇 개의 필터냐 혹은 몇 종류의 특징을 뽑을 거냐 그게 이 개에 해당되는 겁니다. 



개채행열이. 그래서 이 개채행열만 알고 있으면 이 4D 텐서에 대해서 이렇게 shape이 있을 때 헷갈림이 없어요.

강사 24:30
뭐 CIFAR-10 이런 거 해보셨으면은 얘는 배치 사이즈가 만약에 10이고 이렇게 돼 있으면 32 by 32 짜리 칼라 사진이 32장이 있구나. 
이렇게 딱 이해를 할 수가 있는데 개채행열이 안 돼있으면은 되게 헷갈려 보이는 거죠. 

이게 뭐지? 어떻게 생긴 거지? 이렇게 

앞으로는 개채행열만 있으면은 헷갈릴 일 없습니다. 

좋습니다. 그러면 이 레이어 요 convolution layer 이게 convolution layer  1 convolution layer  2라고 볼 수 있겠죠 convolution layer  1에 필터의 weight shape을 개채행열로 말씀해 주세요. 

시작.



(남, 여) 2 by 3 by 5 by 5



강사 25:15
나이스. 좋습니다. 이거는 곱하기처럼 생겼지만 곱하기는 아니죠 바이라고 읽어주시면 됩니다. 

그냥 사이즈를 얘기해 주는 거예요.

 얘는요. 그러면?



(남, 여) 



강사 25:30
이제 헷갈릴 일이 없는 거예요. 마스터 하신 거예요 나이스 좋습니다. 
자 됐어요 그러면은 이 결과물도 바로 답변하실 수 있겠네요. 
결과물 어떻게 됩니까?



참석자2(여) 25:40
10



강사 25:41

10. 왜? 10개의 특징을 뽑았으니까 그겁니다. 



아주 좋아요. 거기 다 되고. 이어지는 문제. 비슷합니다. 



또 3 by 3 짜리를 convolution 하겠대요. 
그랬을 때 채널의 개수는 어떻게 돼야 됩니까? 웨이트의 채널의 개수는 



(여) 10



(강사) 어 이걸 안 낚이다니. 바로 전 거를 봐야 된다라는 거죠. 

10 그리고 5x5랑 3x3짜리랑 만나면 3x3으로 깎이게 됩니다. 

둘 둘씩 깎인다고 했어요.



강사 26:11
그다음에 그러한 필터 그러한 shape을 가지는 필터 20개를 사용한다. 그러면 여기가 20이 될 거고 출력 여기가 20이 되겠죠

참석자2(남) 26:22
딱 좋았어요.

강사 26:23
아주 잘했었어. 바로 그거예요. 이거를 이 행위를 데이터 32개에 대해서 한다면 여기에 32가 추가되는 거예요.


근데 데이터 개수가 늘어난다고 그래서 모델이 바뀝니까? 여러분들 이거 헷갈리면 안 돼요. 

이거 여기다가 32 적으면 진짜 안 됩니다. 

모델은 그냥 어떤 하나의 데이터에 대해서 그냥 잘 정의가 되어 있는 거고 여러 개의 데이터를 통과시키는 거죠. 

이 인공신경망을 여러 번 통과시켜서 갖다 쌓는 거죠. 

그래서 한 장의 데이터를 통과시키고 한 장의 결과를 얻고. 한 장의 결과? 그래 한 장의 결과를 얻고. 그리고 또 32번째 데이터에 대해서 또 32번째의 결과를 얻고. 그걸 갖다 쌓은 결과가 이렇게 되는 거죠.


그래서 32로 출발. 32 32 32 되고



강사 27:13
여기는 뭐가 늘어나는 게 아니다? 웨이트 셰입이 늘어나는 건 아니다라는 거였습니다. 

오케이 됐어요? 잘 되고 있죠? 혹시 질문 있으신 분? 오케이 가봅시다. 



여기에 또 대학원에서 문제가 많이 나오더라고요. 입학 시험 같은 거에 

커널 사이즈가 1 by 1이라고 합시다. 

그러면 이건 뭐 하게 되는 걸까?

3 by 3 짜리가 이렇게 놓여 있어요. 

여기다가 1 by 1를 한다는 건데 이건 대체 뭘까?

강사 27:51
이렇게 RGB 세 개 채널이 있다고 합시다. 

여기에다가 1 by 1짜리를 convolution 하고 싶은 거예요. 

그럼 여기 채널 개수 어떻게 돼요? 무조건 앞에 거 채널 수를 맞추라고 했습니다.

3입니다. 그러면 얘는 물론 이 거를 또 여러 개 쓸 수 있는 거예요. 

이 거를 또 여러 개 쓸 수 있는데

강사 28:15
한 개만 쓰다고 생각하고 일단은 가정하고 말씀을 드려보도록 하겠습니다. 

웨이트가 세 개뿐이네요. 그죠? 웨이트가 세 개 뿐이에요. 

여기에 weight 1 여기에 웨이트 2 여기에 웨이트 3 이런 식으로 곱해지는 거네요. 

그러고 나서 한 칸 이동 w 12 3 곱해가지고 더 하고, 한 칸 이동 w 12 3 곱하고 더하고, 한 칸 이동

강사 28:43
더블유에서 어 이건 뭐지? 이거는 그냥 이렇게 생각하면 안 될까요? 여기 전체에 그냥 w1 곱하는 거 아니에요? 그리고 여기 전체에는 w2가 곱해지는 거 아닙니까? 그리고 여기 전체에는 w3가 곱해져서 이 세 개의 특징 맵 혹은 어쨌든 이 입력 채널 수에 대해서 더하는 거 아니겠습니까? 말하자면 이게 피처맵 1이라고 쳐요.

강사 29:13
피처맵2 이게 피처맵3이라고 합시다. 

그럼 얘는 뭐다? 피처맵끼리 무슨 sum 하는 거예요? 이걸 무슨 sum이라고 불러요?



참석자2(여) 29:30
weighted sum?



강사 29:32
그렇습니다. 그래서 여기다 한번 써주세요. 
피처맵 간에 같이 써보는 거예요. 피처 맵 간의 웨이티드 섬입니다. 

이렇게 그럼 피처맵 간의 웨이티드 섬을 하는데 이 웨이트를 학습한다라는 건 어떤 의미인가요?



강사 30:05
어떤 피처가 더 중요한지 혹은 어떤 피처를 덜 중요하게 볼지를 학습시키는 거다라는 거죠. 

그게 원바이원 컨벌류전인 거예요. 

자 원바이원 컨벌루션은 피처 맵 간의 웨이티드 섬을 함으로써 피처 맵을 만드는 건데. 

그 웨이트는 학습이 되기 때문에 어떤 특징을 중요하게 볼까 조절해가지고 웨이티드 섬에서 피처맵을 만드는 그 행위를 하는 게 바로 원방원 컨벌루션이다라는 겁니다. 

이해 됐어요? 무슨 말인지? 이게 이게 또 중요한 겁니다. 





그러면 여기서 정리해 보도록 하겠습니다. 

필터의 개체를 있잖아요. 정해줘야 할 파라미터는 뭡니까? 그러니까 뭐, 개요 채널이요 행이요 열이요 이렇게 답해주시면 돼요. 

뭐를 정해주셔야 돼요?



강사 31:07
개 정해줘야 겠죠 그쵸 개 행 열 

나이스 

몇 개의 특징을 뽑아야 되느냐 정해주셔야 되고요. 

취사 선택입니다. 마치 우리가 fully connected 할 때 몇 개의 node를 쓸까요? 니 마음대로 똑같은 거예요. 

몇 개의 특징을 뽑을까요? 내 마음 행렬은 얼마나 볼까요? 내 마음

어느 정도의 영역을 볼까요라는 거죠. 

이 행렬을 본다는 것은 어느 정도의 영역을 보고 값을 만들까요? 정해주셔야 된다. 

다만 채는 정해지는 것이다. conv 2D에서는 정해진다. 정해진다. 

오케이 좋습니다. 넘어가 보겠습니다. 

넘어갈까요 여러분

강사 31:50
파란색 한번 질문 혹시 있으면은 빨간색 눌러주시고 제가 확인하도록 하겠습니다.
왔네 없네 아닌가 내가 못 봤나
좋습니다. 넘어가세요. 



![Legend 13-021]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-021.jpg)

convolution에 옵션들이 있죠 패딩과 스트라이드

패딩을 안 이건 너무 간단하죠 그죠? 패딩을 왜 하냐 사이즈만 사이즈를 그대로. 사이즈를 내 마음대로 조절하기 위해서 



![Legend 13-022]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-022.jpg)

스트라이드는 하나씩 하나씩 이동하면서 보는 건 너무 너무 세세하게 보는 거니까 그렇게 까지 디테일하게 볼 필요 없다는. 이미지라는 건 생각보다 많은 정보는 버려져야 돼요.

그러니까 선택과 집중을 잘 해야 되는 거예요. 모든 픽셀을 다 중요시 보면 안 된다라는 거죠. 

강아지를 보는 데 있어서 저 뒤에 풀떼기에 픽셀 값을 쳐다보고 있으면 그거 얼마나 눈물 겨운 일입니까 그렇게 학습할 수 없다라는 거죠. 



이렇게 성큼성큼 가다라는 뜻이 있어가지고 이렇게 뛰어오게 했고요. 

stride(2,2)를 보여주고 있는 겁니다. 

이행 이열 두 칸씩 뛰어라.



![Legend 13-023]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-023.jpg)



강사 33:17
pooling은 사이즈를 줄어서 대표하는 겁니다. 
대표하는 거 pooling 연산 자체는 아실 텐데 이거의 의미는 이 영역에서 대표가 누구냐 이렇게 뽑는다라는 거 선출 선출 한 명씩 한 명씩 뽑는데 

GAP는 섞는다라는 거죠. 

여기서는 짱만 뽑는 거고 짱만 나와 이 반에 짱이 누구야. 

여기는 다 같이 힘을 합치는 거죠.

강사 33:43

평준화하는 거죠. 평준화가 딱 되는 거 그런 느낌으로 보시면 돼요. 

이게 이 행위를 각 채널마다 하죠 그래서 채널이 개수는 바뀐다 안 바뀐다? 바뀌지 않는다라는 겁니다. 

있습니다. 만약에 입력된 사이즈가 지금 4x4죠 그 사이즈랑 똑같게 pooling을 할 때 4 by 4로 이미지 사이즈를 주면은

강사 34:06

그것은 글로벌한 어떤 처리를 한다고 그래서 global average pooling 이렇게 불러요. 

만약에 pooling을 average pooling을 한다면 max pooling이라 그러면 어떻게 될까요? 그러면 그러면 global max pooling 이렇게 부릅니다.


주로 우리는 global average pooling을 쓰기 때문에 이거를 말씀드렸고 쉽게 말하면 전체에 대해서 평균값 구하는 거죠. 

이것도 각 채널마다 평균값을 구한다라고 보시면 되겠습니다. 

그래서 convolution의 두 가지 옵션

강사 34:37
패딩과 스트라이드 배웠고 그리고 새로운 레이어인 pooling이라는 레이어를 배운 거예요. 

이 두 가지 레이어를 번갈아가면서 우리는 많이 사용을 합니다. 

그렇죠? 



![Legend 13-024]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-024.jpg)

conv - pooling - conv - pooling 이런 식으로 

여기서 한번 복습해볼까요? 첫 번째 convolution 여기서 몇 개의 특징을 뽑은 거예요 이것만 딱 보면. 좋습니다. 

여기서는 네 개. 그래서 이런 식으로

강사 35:03
개는 사실은 정해주는 거라고 했어요. 

내 맘대로 정하는 거긴 한데, 대부분은 가면 갈수록 점점 더 많은 특징을 뽑게끔 해요. 

그리고 pooling을 하다 보니까 필연적으로 하나의 픽셀이 많은 영역을 넓은 영역을 대표하게 돼요. 

마치 이 20이 이 영역을 대표하듯이, 이 녀석의 이 결과물의 이 녀석 이 픽셀은 여기서 한 4x4 정도를

대표하는 어떤 값이다라고 볼 수 있는 거예요. 

이 영역을 대표하는 녀석이다. 나는. 이렇게 생각해 줄 수가 있다라는 거고요. 



![Legend 13-025]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-025.jpg)

그러면 계속 그렇게 conv - pooling - conv - pooling 하다 보면 사이즈가 엄청 작고 채널 개수가 많아지겠다. 

이거를 그냥 이렇게 표현해줄 수가 있어요. 

의미적으로. 왜 그러냐면 일단 여러 개 채널을 가지고 있는데 그 각 채널은 각각 특징을 담당하겠죠? 

나는 잔디. 채널 나는 잔디만 볼 거야. 

나는 코 채널. 나는 코만 볼 거야. 

이렇게 채널들이 놓여져 있는 거고 

그리고 저 위에 그림은 각 위치에서 가장 큰 값이 존재하는 채널 이름을 써준 겁니다. 

그러면 저렇게 의미적으로 표현해줄 수 있겠다는 거예요

예를 들면 여기. 여기 위치에 해당되는 픽셀 값들이 채널 축으로 쭉 있을 거잖아요. 

이렇게 쭉 놓여 있을 건데 그중에 가장 큰픽스의 값을 꼭 뽑았을 때 여기에 놓인 녀석이다라는 거예요. 

그래서 그러면 여기에는 귀가 있네 이렇게 얘기를 해줄 수 있겠다라는 겁니다. 

오케이?



참석자2(여) 36:41
네

강사 36:42

됐어요. 오케이 됐습니다. 이 녀석을 이렇게 해주면 그리고 나중에는 MLP를 통과시켜 

얘를 fully connected를 왜 안 쓴다 너무 세세하게 본다고 그랬어요. 

지금은 세세하게 볼 때예요. 충분히 특징을 뽑았습니다. 

이 위치에는 어떤 특징이 있고 이 위치에 어떤 특징이 있고 이렇게 뽑았으면 그럼 이제는 fully connected도 하면 된다라는 거예요.

강사 37:09

MLP 통과를 시켜가지고 다중분류죠 노드 3개로 빼면은 다중 분류 3 개 분류를 하는 거죠. 

강아지 값이 가장 크도록 학습을 시키면 되겠다 라는 겁니다. 



![Legend 13-026]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-026.jpg)

근데 진짜로 피처앱이 이런 식으로 털털 잔디 잔디 이런 식으로 생겼을까 궁금해서 이런 컨벌루션을 학습을 시켜봤고 지금 보면 nn.sequential로 conv 2개 묶여 있죠 

그리고 pooling 

그다음에 conv 3개

pooling 

그다음에 conv 3개 

남플링 이런 식으로 한번 구성을 해봤어요. 

그냥 만들어본 거고 CIFAR-10 데이터에 대해서 84.4% 정도의 정확도를 가지는 그런 모델이 탄생을 했습니다. 

여기다가 대고 한번 강아지 사진을 넣어본 거예요.

 

넣어봤을 때 conv block 1 2 3 통과하면서 이런 식으로 바뀌더라. 

다시 conv  block 1 통과

여기까지 통과한 그림을 본 거예요. 

그러면 32개의 특징 맵이 나오겠죠 



그다음에 여기까지 통과한 거 64개 앱이 나오겠죠 



그 다음 여기까지 통과한 거 128개의 특징 결이 나올 겁니다. 



걔네들을 한번 쫙 펼쳐놓고 야 뭔 특징을 본 거냐 이거 한번 맞춰보자 생각을 해보자 해석을 해보자라는 겁니다. 



![Legend 13-027]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-027.jpg)

한번 보니까 첫 번째 conv block 1에서는 뭔가 특징을 뽑는 거 같은 거예요. 

어떤 특징 획특징을 뽑는 것 같다라는 겁니다.

강사 38:31
얘는 이런 대각선 

얘는 뭔가 굵은 세로 굵은 세로 특징 

얘는 가로 

그러니까 굵고 뭐 자시고 이거는 convolution 두 번 세 번 통과시키면 점점 굵은 선을 찾아들어갈 수가 있는 겁니다. 

여기는 이쪽 여기는 이쪽 여기는 세로 여기도 여기 굵은 세로 

여기는 배경이랑 분리를 한 것 같아요. 

배경 평평한 거를 본 거죠

평평한 부분인지 아닌지 여러 가지 것들 

이렇게 이런 식으로 획을 뽑는. 여기 잘 보인다. 

세로 특징 잘 보고 있습니다. 

여기도 가로 특징을 잘 보고 있습니다.

이렇게 이렇게 이렇게

그게 좋아요. 그게 conv block 1의 통과 결과 그림이라는 거고 



![Legend 13-028]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-028.jpg)

conv block 2쯤 통과하니까 뭔가 이 선들을 이용해서 좀 더 복합적인 특징을 뽑는 거 같은데 라는 거예요. 

무슨 말이냐면 맨 처음에 입력이 들어갔겠죠 그래가지고 이 입력에 대해서 막 획을 뽑은 거예요. 

가로도 뽑고요. 세로는 다리가 있으니까 세로도 뽑고요.

여기도 이렇게 있다고 치죠. 

그다음에 대각선도 뽑고요. 

이런 식으로 여러 특징을 뽑겠죠 

convolution block을 통과시켰을 때

자, 어떻게 할까요 그 다음에 요렇게 하나? 어 그다음에 

어차피 3 by 3은 되게 작잖아요. 

 3 by 3은 되게 작은 영역만 보니까 1x1이라고 생각할게요. 

1x1 1x1에 의해서 통과를 한다고 생각해 보겠습니다. 

그러면 이 피처맵들을 어떻게 하는 거라고요?



(남) weighted sum?



강사 40:24
웨이티드 섬을 하는 거랬어요. 

그 말은 어떤 특징이 더 중요한지 덜 중요한지를 보고 이 다음 피처맵 만든다라는 거예요.

그래서 뭐 예를 들면 1 1 0 이렇게 학습이 됐다 칩시다. 

이건 그냥 그냥 제 마음대로 한번 정해본 거예요. 

그러면 어떻게 되는 거예요? 그림이 

두 번째 convolution block에서 

이거를 그림을 그리고 있는 거예요. 

이렇게 이렇게 딴 딴 딴 딴

강사 40:46
그게 이런 식으로 좀 복합적인 그림 세로도 있고 가로도 있는 것처럼 보이게 된다라는 겁니다. 

세로도 있고 가로도 있고 

그렇죠 여기도 좀 더 복합적인 여기도 

윤곽이 싹 예쁘게 떴어요. 

이거 이거 이거 골고루 잡았어요. 

대각선도 보고 이쪽 대각선도 보고 이쪽 대가.. 이쪽 가로선 세로선 골고루 다 봐줬습니다. 

그 결과를 지금 보고 있는 것 같다라는 겁니다. 

오케이?

강사 41:15 

만약에 그러면은 어떻게 할까? 

얘랑 얘랑 봤어요 얘랑 얘랑 얘랑 보고 얘를 안 봤어요 그러면은 요래 요래 요래 요래 요래 이런 식으로 상체만 본다든가 하체를 안 보고 상체만 본다든가 이렇게 되는 거예요. 

이해 됐어요?

참석자2(여) 41:41
네

강사 41:42
그렇게 해서 64개나 뽑은 거죠. 점점 더 많은 채널을 뽑습니다. 



![Legend 13-029]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-029.jpg)

그다음에 마지막 convolution block 3을 통과했더니 pooling이 많이 돼가지고 이제는 그냥 여기에 뭐가 있어 여기엔 뭐가 있어 이렇게만 얘기를 해주고 있어요. 

그러니까 얘를 들면 얘는 얘는 앞발이 있어. 

앞발 피처를 뽑은 거 같아요. 앞발 피처 앞발 피처맵. 얘는 머리 귀 귀 귀

강사 42:13
얘는 머리 딱 머리 맞죠. 얘는 또 누구 있을까? 앞다리

강사 42:26
뒷다리 한번 찾아주세요. 뒷다리가 있었는데 어디 좋은 게 있었는데

참석자2(남) 42:36
가운데 쪽에 있는 건지



(강사)

뭐라고?



(남) 좀 더 위에 두칸 오른..



(강사) 요런 놈? 요놈 요놈 요놈. 



(남) 네네



(강사) 뒷다리

좋습니다



강사 42:49
그래 이렇게 각자가 어떤 특징을 담당해서 뽑아내고 있다는 거예요. 

나는 이 특징 볼래. 나는 이 특징 볼래. 이런 식으로 보인다라는 거죠. 

근데 128 개나 되니까 조금 애매해요. 너무 많아. 너무 많아서 좀 알기가 힘들어서 싹 더해봤습니다. 



![Legend 13-030]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-030.jpg)

더 해봤더니 이렇게 나왔어요. 노란색이 값이 큰 겁니다. 

즉 노란 부분에서 뭔가 강한 게 있다는 거예요. 뭔지는 몰라도 일단 다 더해버렸으니까 뭔지 몰라도 하여튼 뭔가 강한 게 있다라고 보고를 하고 있는 겁니다. 



이거를 입력 사진에다가 겹쳐보니까 와우 강아지 머리랑 다리를 집중해서 보더니 강아지를, 이건 레이블입니다. 

강아지라고 예측한 거예요. 정답 맞춘 겁니다.

강사 43:35
그래서 강아지 이 사진 이 사진의 머리랑 다리를 열심히 보더니 강아지라고 딱 예측해버리네. 

와우 굳 이렇게 되는 겁니다. 



![Legend 13-031]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-031.jpg)

틀린 그림도 있어요. 

틀린 그림 틀린 그림도 가져와 봤습니다.


고양이가 상자 위에 이렇게 얼굴을 빼꼼 내밀고 있는 그림이에요. 

깜찍하네요. 그런데 어디를 집중해서 봤습니까?

참석자2(남) 44:00
상자

강사 44:01
성자를 집중해서 보고 있어요. 웬 걸 그러다 보니까 강아지를 고양이라고 착각한 겁니다. 
여기도 보긴 했거든요. 여기도 이렇게 술술 보긴 했는데 가장 진하게 보진 못했어요. 
그래서 만약에 여기에 뭔가 강렬한 뭔가가 있다라고 파악을 했다면 잘 맞췄겠죠 

이건 테스트 사진이에요. 전부 다 테스트 사진이다 보니까 처음 보다 보니까 다른 데에 이렇게 집중을 하더라라는 겁니다. 

그러면서 조금 틀어졌고 그래서 틀린 거죠.



![Legend 13-032]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-032.jpg)

강사 44:29
정답 맞춘 것도 또 볼게요. 그죠? 하늘은 안보고 여기만 열심히 보더니 딱 정답을 맞추는 그런 모습. 아주 좋습니다. 





![Legend 13-033]({{site.url}}\images\2023-10-25-Day1-CNN\Legend 13-033.jpg)

그래서 이거 많이 들어보신 해석일 거예요. 

로레벨로부터 점점 하이 레벨 피처를 뽑는다라는 거 좋습니다. 

그런데 이게 꼭 only 1 어떤 해석은 아니에요. 여러분들만의 나름대로 더 다채로운 해석을 해볼 수가 있고 그냥 무조건 이렇게 훈련된다는, 첫 번째 레이어에서는 획을 뽑고요.  두 번째 레이어에서는 획을 합치고요. 그거는 그냥 수많은 해석 방법 중에 하나고 또 달리 여러분들만의 해석으로 생각하셔도 좋습니다. 

그걸 권장하기도 하고. 



됐습니까? 



(남, 여) 네



(강사)

Ok 좋아요.


이미지넷 챌린지 설명드리고 다음 시간부터 이제 본격적으로 VGGNet부터 시작해서 한번 파헤쳐보도록 하죠.



